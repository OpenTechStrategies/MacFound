#!/bin/bash

# Load all the 100&Change proposals into a wiki, and along the way
# create a 'processed-100andchangeExport-all-judges.csv' file 
# to give to LFC.
#
# Copyright (C) 2017  Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
# 
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

CSV_ONLY=""
PARE=""
while getopts "cp:" opt; do
  case $opt in
    c) CSV_ONLY="--csv-only" ;;
    p) PARE="--pare=$OPTARG" ;;
  esac
done
shift $((OPTIND -1))

COMPETITION="100Change2017"
LFC_DIR=`dirname "${0}"`
BASE_DATA_DIR="${1}"

function check_for_bin {
	command -v $1 >/dev/null 2>&1 || { echo >&2 "$1 required but it's not available.  Aborting."; exit 1; }
}

if [ "${BASE_DATA_DIR}" = "" ]; then
  echo "ERROR: BASE_DATA_DIRECTORY argument required."
  echo ""
  echo "Usage: '${0} [-c] [-p arg] BASE_DATA_DIRECTORY'"
  echo ""
  echo "Options:"
  echo ""
  echo "  -c                  Uploads CSV only.  Skips creating pages and"
  echo "                      uploading attachments."
  echo "  -p <arg>            If ARG is a number, pares by factor of ARG. If"
  echo "                      ARG begins with +, then ARG is a comma separated"
  echo "                      list of keys to include.  If ARG begins with @,"
  echo "                      then ARG is a file with a newline separated list"
  echo "                      of keys to include."
  echo ""
  echo "BASE_DATA_DIRECTORY/100Change2017 is where all the work is done."
  echo ""
  exit 1
fi

DATA_DIR="${BASE_DATA_DIR}/${COMPETITION}"

# Make sure we have csvkit by checking version on csvgrep.
# If we don't have it, one way to get it would be:
#
#   $ git clone https://github.com/wireservice/csvkit.git
#   $ cd csvkit
#   $ sudo python3 setup.py install --prefix=/usr/local
check_for_bin csvgrep
check_for_bin gunzip
csvgrep --version 2&>/dev/null || { echo "csvkit needs to be a recent version. Please upgrade to version 1.0.2+"; exit 1; }

SANITIZER="${LFC_DIR}"/fix-csv
RUNNER="${LFC_DIR}"/compose-and-upload

MASTER_CSV="100andchangeExport-all-judges.csv"
PRINCIPAL_CONTACT_CSV="Principal-contact-join-20170716-utf8.csv"
REASON_FOR_TURNDOWN_CSV="Reason-for-Turndown-join-2017-07-16-utf8.csv"
RECLASSIFICATION_XLSX="geo-and-topic-revisions-Reclassify-themes-ALL-complete-(merged-assignment-docs).xlsx"
RECLASSIFICATION_CSV="geo-and-topic-revisions-Reclassify-themes-ALL-complete-(merged-assignment-docs).csv"
EXCLUDED_REVIEW_NUMBERS_TXT="excluded-review-numbers.txt"
ATTACHMENT_ZIP="Generated-Attachments-From-Mediawiki.zip"
OTS_CORRECTION_FILE="OTS_Corrections.csv"

ATTACHMENTS_DIR="${DATA_DIR}/attachments/"
TDC_CONFIG_DIR="${DATA_DIR}/tdcconfig/"

if [ ! -d "${DATA_DIR}" ] ; then
  echo "Stage 0: Setting up data directory..."

  if [ "${OTS_DIR}" = "" ] ; then
    echo "ERROR: \$OTS_DIR is not set up"
    echo ""
    echo "See bureaucracy/onboarding about setting the OTS_DIR environment variable up"
    exit 1
  fi

  ENCRYPTED_DIR="${OTS_DIR}/clients/lever-for-change/torque-sites/${COMPETITION}/data/bigdata"
  if [ ! -d "${ENCRYPTED_DIR}" ] ; then
    echo "ERROR: it looks like your encrypted dir isn't checked out"
    echo ""
    echo "It was expected to be in:"
    echo "  $ENCRYPTED_DIR"
    echo ""
    echo "You will need to check out the subversion torque-sites data, and then"
    echo "run get-bigdata from ${OTS_DIR}/clients/lever-for-change/torque-sites/${COMPETITION}/data/"
    exit 1
  fi

  mkdir -p $DATA_DIR

  echo "Decrypting..."
  gpg -o ${DATA_DIR}/${MASTER_CSV}.gz --decrypt ${ENCRYPTED_DIR}/${MASTER_CSV}.gz.gpg || exit 1
  gunzip ${DATA_DIR}/${MASTER_CSV}.gz
  cp ${ENCRYPTED_DIR}/${PRINCIPAL_CONTACT_CSV} ${DATA_DIR}/${PRINCIPAL_CONTACT_CSV}
  cp ${ENCRYPTED_DIR}/${REASON_FOR_TURNDOWN_CSV} ${DATA_DIR}/${REASON_FOR_TURNDOWN_CSV}
  cp ${ENCRYPTED_DIR}/${EXCLUDED_REVIEW_NUMBERS_TXT} ${DATA_DIR}/${EXCLUDED_REVIEW_NUMBERS_TXT}
  gpg -o ${DATA_DIR}/${RECLASSIFICATION_XLSX} --decrypt ${ENCRYPTED_DIR}/${RECLASSIFICATION_XLSX}.gpg || exit 1
  gpg -o ${DATA_DIR}/${ATTACHMENT_ZIP} --decrypt ${ENCRYPTED_DIR}/${ATTACHMENT_ZIP}.gpg || exit 1
  gpg -o ${DATA_DIR}/${OTS_CORRECTION_FILE} --decrypt ${ENCRYPTED_DIR}/${OTS_CORRECTION_FILE}.gpg || exit 1

  mkdir -p ${ATTACHMENTS_DIR}
  mkdir -p ${TDC_CONFIG_DIR}

  unzip -d ${ATTACHMENTS_DIR} ${DATA_DIR}/${ATTACHMENT_ZIP}

  # To save harddisk space, we remove the zip
  rm ${DATA_DIR}/${ATTACHMENT_ZIP}

  in2csv ${DATA_DIR}/${RECLASSIFICATION_XLSX} > ${DATA_DIR}/${RECLASSIFICATION_CSV} 
fi

# We've extracted the excluded Review Numbers from Exclusions.xlsx.
# They're saved elsewhere, but for the record, here's how it was done,
# using the 'in2csv' program from csvkit:
# 
#   $ in2csv ${DATA_DIR}/Exclusions.xlsx > ${DATA_DIR}/Exclusions.csv
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 0 has no name. Using "a".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 1 has no name. Using "b".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 2 has no name. Using "c".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 3 has no name. Using "d".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 4 has no name. Using "e".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 5 has no name. Using "f".
# 
#   $ csvcut -n ${DATA_DIR}/Exclusions.csv
#   1: a
#   2: b
#   3: c
#   4: d
#   5: e
#   6: f
# 
#   $ csvlook ~/private/work/ots/clients/lever-for-change/.../data/.../Exclusions.csv
#   ...see from output that column "a" has the Review Numbers we want...
# 
#   $ csvcut -c a ~/private/work/ots/clients/lever-for-change/.../data/.../Exclusions.csv \
#           | grep -E "[0-9]+" > ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ cat ${DATA_DIR}/excluded-review-numbers.txt
#   6587
#   6226
#   72
#   671
#   1095
#   1723
#   2681
#   4046
#   5861
#   6381
#   6728
#   6882
#   5653
#   3030
#   5073
# 
#   $ svn add ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ svn ci -m "Save excluded Review Numbers (based on Exclusions.xlsx)." \
#                     ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ 

# First we sanitize, then we filter, then we join.  We leave all the
# intermediate stages in place, in case we need to debug them later.
STAGE_1_PREFIX="sanitized-"
STAGE_2_PREFIX="filtered-"
STAGE_3_PREFIX="joined-"
STAGE_FINAL_PREFIX="processed-"

STAGE_1_CSV="${STAGE_1_PREFIX}${MASTER_CSV}"
STAGE_2_CSV="${STAGE_2_PREFIX}${MASTER_CSV}"
STAGE_3_CSV="${STAGE_3_PREFIX}${MASTER_CSV}"
STAGE_FINAL_CSV="${STAGE_FINAL_PREFIX}${MASTER_CSV}"

### Sanitize the updated spreadsheet.
#
# Use --pare to convert only 1% of the entries, to save time while testing. 
echo "Stage 1: Sanitizing..."
${SANITIZER} --reclassifications="${DATA_DIR}/${RECLASSIFICATION_CSV}" \
             "${DATA_DIR}/${MASTER_CSV}" \
             "${DATA_DIR}/${STAGE_1_CSV}"
if [ $? -ne 0 ]; then
		echo Sanitization failure!
		exit 1
fi
echo "Done with Stage 1 (sanitizing)."
echo ""

### Filter out excluded Review Numbers.
echo "Stage 2: Filtering excluded Review Numbers..."
csvgrep -c 15 -f "${DATA_DIR}/${EXCLUDED_REVIEW_NUMBERS_TXT}" -i \
        "${DATA_DIR}"/${STAGE_1_CSV} > "${DATA_DIR}"/"${STAGE_2_CSV}"
echo "Done with Stage 2 (filtering excluded Review Numbers)."
echo ""


### Splice (join) in two columns from supplemental CSVs supplied by LFC.
#
# We're going to add a "Participant_Email" column and supplant the old
# "Reason_For_Turndown" column with the new Reason_For_Turndown.
#
# In the latter case, the new column will be at a slightly different
# position than the original.

echo "Stage 3: Adding some supplemental data..."
# First, gather the two new columns into a single CSV, keyed
# by Review_Number (that's our 'join' key).
#
# Start by isolating the participant contact email into a CSV that has
# just the Review_Number and the contact email.
csvcut -c Review_Number,Participant_Email                             \
          "${DATA_DIR}/${PRINCIPAL_CONTACT_CSV}"                      \
        > "${DATA_DIR}"/participant-email-tmp.csv
# Side cleanup: fix the email addresses to use entities instead of
# literal angle brackets, because with literal angle brackets, writing
# them to MediaWiki via mwclient causes surprious HTML-style closing:
# "Foo Bar <foobar@example.com>" would be turned into
# "Foo Bar <foobar@example.com></foobar@example.com>".
sed -E "s/ <([^ <>]+)>/ \\&lt;\\1\\&gt;/g"                            \
       "${DATA_DIR}"/participant-email-tmp.csv                        \
    > "${DATA_DIR}"/participant-email-tmp.csv.tmp
mv "${DATA_DIR}"/participant-email-tmp.csv.tmp                        \
   "${DATA_DIR}"/participant-email-tmp.csv
# Next, isolate reason for turndown in the same way we did participant
# contact email.
csvcut -c Review_Number,Reason_For_Turndown                           \
          "${DATA_DIR}/${REASON_FOR_TURNDOWN_CSV}"  \
        > "${DATA_DIR}"/reason-for-turndown-tmp.csv
# Join those two into one new CSV, also keyed on Review_Number.
#
# The '--left' ensures that the temporary combined supplementary
# spreadsheet, which contains both principal contact info and reasons
# for turndown, is complete, that is, that it represents the union of
# those two sets of review numbers.
csvjoin --left -c Review_Number                                       \
           "${DATA_DIR}"/participant-email-tmp.csv                    \
           "${DATA_DIR}"/reason-for-turndown-tmp.csv                  \
         > "${DATA_DIR}"/contact-and-turndown-tmp.csv
# Ah, but that leaves three missing Review_Numbers, ones that were in
# Reason-for-Turndown-join-2017-07-16-utf8.csv but were not in
# Principal-contact-join-20170716-utf8.csv.  That's okay.  Three's a
# pretty low integer -- we can just handle them manually.  Note that
# we *could* figure them out on the fly here, and if we ever get
# updated supplemental data from LFC, then we should probably
# dynamicize this code.  But for now, we just know 8002, 8005, 8009.
for num in 8002 8005 8009; do
  grep -E "^${num}," "${DATA_DIR}"/reason-for-turndown-tmp.csv        \
    | sed -e "s/,/,,/g"                                               \
  >> "${DATA_DIR}"/contact-and-turndown-tmp.csv;                      \
done
# Now the last three rows of $DATA_DIR/contact-and-turndown-tmp.csv
# look like this (with the actual reasons omitted of course):
# 
#   8002,,Real reason for turndown omitted from this public script
#   8005,,Same here
#   8009,,Likewise
#
# ...which is exactly what we needed: three rows that give a new
# reason for turndown, but don't supply a principal contact (because
# Principal-contact-join-20170716-utf8.csv didn't have any for them).
#  
# Cut the old Reason_For_Turndown column out of the original CSV.
csvcut -C Reason_For_Turndown                                         \
          "${DATA_DIR}"/"${STAGE_2_CSV}"                              \
        > "${DATA_DIR}"/tmp-"${STAGE_2_CSV}"
# Put in the new Participant_Email and Reason_For_Turndown columns.
#
# The '--left' here ensures that proposals whose review numbers do not
# appear at all the combined supplementary spreadsheet (i.e.,
# proposals for which there is neither a supplemental principal
# contact nor a supplemental reason for turndown) are still included
# in the final spreadsheet and thus in the wiki.
# 
# This works because:
#
#    - Principal Contact Info isn't a field in the original
#      spreadsheet anyway, so we by definition can't drop it.
#
#    - We were told that the supplemental Reasons For Turndown are a
#      strict superset of the Reasons For Turndown as given in the
#      original spreadsheet, so the fact that we dropped the original
#      column and replaced it with this data can't lose information.
#      And by "can't happen" I mean "\"can't happen\"".
#
#    - As I wrote this comment, in the Starbucks at 55 Broad Street in
#      lower Manhattan, the Jackson 5's "I Want You Back" came on
#      their sound system and was filling the room with awesomeness,
#      but then somehow whatever streaming company is supplying
#      Starbucks with awesomeness decided to do a *fade out* on that
#      song, even though if ever a song deserved to go out with its
#      proper ending it's that one.  I just want to promise that we
#      will never treat your data the way they treated that song.
csvjoin --snifflimit=0 --delimiter=',' --quotechar='"'                \
        --left                                                        \
        -c Review_Number                                              \
           "${DATA_DIR}"/tmp-"${STAGE_2_CSV}"                         \
           "${DATA_DIR}"/contact-and-turndown-tmp.csv                 \
         > "${DATA_DIR}"/"${STAGE_3_CSV}"
# Note that the last step above changed some column numbers:
#
#                            OLD       NEW
#                            ---       ---
#  Comments                   89        88
#  Pitch Video Link           90        89
#  Participant_Email         N/A        90
#  Reason_For_Turndown        88        91
echo "Done with Stage 3 (joining CSVs to add supplemental data)."
echo ""

# Give the processed CSV its final name, for delivery to LFC.
cp "${DATA_DIR}"/"${STAGE_3_CSV}" "${DATA_DIR}"/"${STAGE_FINAL_CSV}"

### Upload the spreadsheet and TOCs to a running instance of torquedata
#
# There's a dependency on a running version of mediawiki
# with a torquedata service running behind it, and a version of
# the TorqueDataConnect running on the mediawiki
#
# Because attachments take a bit of time to upload, and we have no current
# method to see if they have been uploaded, we just use a simple environment
# variable to test if someone wants to.
echo "Stage 4: Uploading csv and attachments..."
echo "  If you want to skip attachments, set SKIP_ATTACHMENTS in your environment"
${RUNNER} --proposals-csv="${DATA_DIR}/${STAGE_FINAL_CSV}" \
          $PARE \
          $CSV_ONLY \
          --tdc-config-dir="${TDC_CONFIG_DIR}" \
          --attachments-dir=${ATTACHMENTS_DIR} \
          --correction-file="${DATA_DIR}/${OTS_CORRECTION_FILE}"
if [ $? -ne 0 ]; then
		echo Upload failure!
		exit 1
fi
echo "Done with Stage 4 (Uploading csv)."
