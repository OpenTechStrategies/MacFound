#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Copyright (C) 2017, 2019, 2020 Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

__doc__ = """\
Compose all of the Lever for Change 2020 Proposal CSV files.

Usage:

  $ compose-csvs \\
       --proposals-csv=PROPOSALS_CSV \\
       --admin-review-csv=ADMIN_REVIEW_CSV \\
       --judge-evaluation-csv=JUDGE_EVALUATION_CSV \\
       --wisehead-evaluation-csv=WISEHEAD_CSV \\
       --sdgconfig-csv=SDGCONFIG_CSV \\
       --attachments-dir=ATTACHMENTS_DIR \\
       --correction-file=COORECTION_FILE \\
       --tdc-config-dir=TDC_CONFIG_DIR \\
       --pare=PARE \\
       --csv-only

Command-line options:
  --proposals-csv FILE            FILE is a CSV file representing the bulk
                                  of the proposal information

  --admin-review-csv FILE         FILE is a CSV file representing which applications
                                  in PROPOSALS_CSV should be included

  --judge-evaluation-csv FILE     FILE is a CSV file with a many to one relationshp
                                  between judges and the proposals they evaluated,
                                  with the extra data being their evaluation

  --wisehead-evaluation-csv FILE  FILE is a CSV file with a many to one relationship
                                  between wisehead judges and the proposals they
                                  evaluated, like the judge-evaluation-csv

  --correction-file FILE          FILE is a csv of corrections to the main data.  The header
                                  must match the header of the original proposals file, and any
                                  one of the columns must contain the review number.  Then
                                  the data from the correction file will override the
                                  source data for output.  There can be multiple correction
                                  files, and each one overwrites the previous.

                                  If the data cells have the empty string, no correction is applied.

  --ots-metadata FILE             FILE is a csv of MetaData created by OTS to use when creating
                                  the final spreadsheet.  Each row defines a given override attribute
                                  for a given review number, and what value should go there.
                                  This spreadsheet grows as the ETL pipeline one-off needs grow.

  --sdgconfig-csv FILE            FILE is a csv of sdg configurations, that when provided
                                  will be checked against in the SDG column for validation
                                  and separation into a list.

  --attachments-dir DIR           DIR is a directory for compose-csvs to look in for what attachments
                                  will be uploaded to the torque wiki.  It needs to have subdirectories
                                  by proposal number.

  --tdc-config-dir DIR            DIR is the location for files that are the base configuration files
                                  needed by TorqueDataConnect, and can be optionally, manually, put on
                                  the torque wiki.  We don't automatically do that because we want to
                                  overwrite the configuration out there.

  --pare ARG                      If ARG is a number, reduce the number of items to 1/ARG.  If
                                  ARG begins with +, then ARG is a comma separated list of
                                  keys to include.  If ARG begins with @, then ARG is a
                                  file with a list of keys to include.  For both + and @,
                                  the list of keys will be limited to only the ones provided.

  --csv-only                      Only upload the created CSV file.  Don't upload attachments or
                                  create wiki pages.  For use to speed up process when wiki has been
                                  created already.

"""

from etl import competition, wiki, toc, tdc, utils
import config
import getopt
import sys
import os
import re
import csv


def process_sdgconfig_data(sdgconfig_csv):
    """Takes a CSV_READER representing a valid sdgs, and their number
    and converts it into a dict representing a lookup by sdg.
    If no reader is provided, then None is returned.

    The return object, when CSV_READER is present is of the form:
      SDG_DATA[name] = {
        number: integer
      }
    """

    reader = csv.reader(
        open(sdgconfig_csv, encoding="utf-8"), delimiter=",", quotechar='"'
    )
    next(reader)
    return [{"name": row[1], "number": row[0]} for row in reader]


def process_ots_metadata(ots_metadata_file):
    """Process READER into a dictionary that's contextual based
    on what metadata ots needs to process the ETL pipeline.  This
    changes as special cases are brought up.  It returns an object
    where the attribute (column 1), maps to the value (column 2)
    for the given review number (column 0). The top level object is
    keyed on the review number.

    For instance:

    Review Number,Attribute,Value
    1,Wild Card,yes

    maps to

    { "1": { "Wild Card": "yes" } }
    """
    reader = csv.reader(
        open(ots_metadata_file, encoding="utf-8"), delimiter=",", quotechar='"'
    )
    header = next(reader)

    metadata = {}
    for row in reader:
        review_number = row[0]
        attribute_name = row[1]
        value = row[2]

        if review_number not in metadata:
            metadata[review_number] = {}

        metadata[review_number][attribute_name] = value

    return metadata


def create_tdc_config(tdc_config_dir, comp):
    """Helper method to write out base config files to TDC_CONFIG_DIR.

    Needs HEADER_ROW and NEW_ROWS to generate the column and proposal
    data.  Generates the following:

      - AllProposals - All the proposals generated
      - Top100 - The top 100 proposals
      - Top100AndWildCards - the above but with the 113 declared wildcards
      - FinalistCandidates - the top 100, with wild cards, but omitting TR Disqualified
      - Top200 - The top 200 proposals
      - PassedReview - The ~455 proposals that passed wisehead review
      - AllColumns - All the available columns
      - ApiColumns - The columns used in v1 of the API
      - NonReviewColumns - The columns excepting ones relating to reviews
    """

    tdc.AllProposals(comp).generate(tdc_config_dir)
    tdc.ValidProposals(comp, "Valid", "Valid").generate(tdc_config_dir)
    tdc.AllColumns(comp).generate(tdc_config_dir)
    tdc.ProcessedSpreadsheet(comp).generate(tdc_config_dir)

    with open(os.path.join(tdc_config_dir, "Top100"), "w") as f:
        f.writelines(
            [
                tdc.proposal_to_title_line(p)
                for p in comp.ordered_proposals()
                if int(p.cell("Wise Head Overall Score Rank Normalized")) < 101
            ]
        )

    with open(os.path.join(tdc_config_dir, "Top100AndWildcards"), "w") as f:
        f.writelines(
            [
                tdc.proposal_to_title_line(p)
                for p in comp.ordered_proposals()
                if (
                    int(p.cell("Wise Head Overall Score Rank Normalized")) < 101
                    or p.cell("Wild Card") == "Wild Card"
                )
            ]
        )

    with open(os.path.join(tdc_config_dir, "FinalistCandidates"), "w") as f:
        f.writelines(
            [
                tdc.proposal_to_title_line(p)
                for p in comp.ordered_proposals()
                if (
                    int(p.cell("Wise Head Overall Score Rank Normalized")) < 101
                    or p.cell("Wild Card") == "Wild Card"
                    and p.cell("TR Disqualified") != "TR Disqualified"
                )
            ]
        )

    with open(os.path.join(tdc_config_dir, "Top200"), "w") as f:
        # 202 here because there was a duplicate removed before
        f.writelines(
            [
                tdc.proposal_to_title_line(p)
                for p in comp.ordered_proposals()
                if int(p.cell("Wise Head Overall Score Rank Normalized")) < 202
            ]
        )

    with open(os.path.join(tdc_config_dir, "PassedReview"), "w") as f:
        f.writelines(
            [
                tdc.proposal_to_title_line(p)
                for p in comp.ordered_proposals()
                if int(p.cell("Wise Head Overall Score Rank Normalized")) != 9999
            ]
        )

    # These are hardcoded here, because where else?  We want this output
    # to go with the other tdc_config outputs, so here is the best place
    # to get into the project and update later.
    with open(os.path.join(tdc_config_dir, "ApiColumns"), "w") as f:
        f.writelines(
            [
                "* Organization Legal Name\n",
                "* City\n",
                "* State\n",
                "* Country\n",
                "* Principal Organization Website or Social Media\n",
                "* Identification Number of Principal Organization\n",
                "* Identification Number of Principal Organization ein\n",
                "* Primary Contact First Name\n",
                "* Primary Contact Last Name\n",
                "* Primary Contact Title\n",
                "* Primary Contact Email\n",
                "* Review Number\n",
                "* Project Title\n",
                "* Project Description\n",
                "* Executive Summary\n",
                "* Problem Statement\n",
                "* Solution Overview\n",
                "* Youtube Video\n",
                "* Location Of Future Work Country\n",
                "* Location Of Future Work2 Country\n",
                "* Location Of Future Work3 Country\n",
                "* Location Of Future Work4 Country\n",
                "* Location Of Future Work5 Country\n",
                "* Location Of Current Solution Country\n",
                "* Location Of Current Solution2 Country\n",
                "* Location Of Current Solution3 Country\n",
                "* Location Of Current Solution4 Country\n",
                "* Location Of Current Solution5 Country\n",
                "* Project Website or Social Media Page\n",
                "* Application Level\n",
                "* Competition Domain\n",
            ]
        )

    review_columns = [
        "Judge Overall Score Rank Normalized",
        "Judge Sum of Scores Normalized",
        "Judge IMPACTFUL",
        "Judge IMPACTFUL Score Normalized",
        "Judge IMPACTFUL Comments",
        "Judge EVIDENCE-BASED",
        "Judge EVIDENCE-BASED Score Normalized",
        "Judge EVIDENCE-BASED Comments",
        "Judge FEASIBLE",
        "Judge FEASIBLE Score Normalized",
        "Judge FEASIBLE Comments",
        "Judge DURABLE",
        "Judge DURABLE Score Normalized",
        "Judge DURABLE Comments",
        "Wise Head Sum of Scores Normalized",
        "Wise Head IMPACTFUL",
        "Wise Head IMPACTFUL Score Normalized",
        "Wise Head IMPACTFUL Comments",
        "Wise Head EVIDENCE-BASED",
        "Wise Head EVIDENCE-BASED Score Normalized",
        "Wise Head EVIDENCE-BASED Comments",
        "Wise Head FEASIBLE",
        "Wise Head FEASIBLE Score Normalized",
        "Wise Head FEASIBLE Comments",
        "Wise Head DURABLE",
        "Wise Head DURABLE Score Normalized",
        "Wise Head DURABLE Comments",
    ]

    with open(os.path.join(tdc_config_dir, "NonReviewColumns"), "w") as f:
        for column in comp.columns:
            if column not in review_columns:
                f.writelines("* %s\n" % column)


class ApplicationLevelAdder(competition.InformationAdder):
    """Adds the Application Level column, which is a special API field"""

    def column_names(self):
        return ["Application Level"]

    def cell(self, proposal, column_name):
        if (
            int(proposal.cell("Wise Head Overall Score Rank Normalized")) < 101
            or proposal.cell("Wild Card") == "Wild Card"
        ) and proposal.cell("TR Disqualified") != "TR Disqualified":
            return "Highly Ranked"
        else:
            return "NULL"


class WildcardAdder(competition.InformationAdder):
    """Adds whether this proposal is a wildcard"""

    def __init__(self, ots_metadata):
        self.ots_metadata = ots_metadata

    def column_names(self):
        return ["Wild Card"]

    def cell(self, proposal, column_name):
        return self.ots_metadata.get(proposal.key(), {}).get("Wild Card", "")


class WildcardEligibleAdder(competition.InformationAdder):
    """Adds whether this proposal is wildcard eligible"""

    def column_names(self):
        return ["Wild Card Eligible"]

    def cell(self, proposal, column_name):
        rank = int(proposal.cell("Wise Head Overall Score Rank Normalized"))
        return "Wild Card Eligible" if rank > 100 and rank <= 201 else ""


class TRDisqualifiedAdder(competition.InformationAdder):
    """Adds whether this proposal has been disaqualified upon review"""

    def __init__(self, ots_metadata):
        self.ots_metadata = ots_metadata

    def column_names(self):
        return ["TR Disqualified"]

    def cell(self, proposal, column_name):
        return self.ots_metadata.get(proposal.key(), {}).get("TR Disqualified", "")


class AppendixDisplayNamesAdder(competition.InformationAdder):
    """Adds a list matching the Prospectus Appendix Attachments for the names"""

    def column_type(self, column_name):
        return "list"

    def column_names(self):
        return ["Names of Prospectus Appendix Attachments"]

    def clean(self, attachment):
        retn = re.sub(".pdf", "", attachment)
        retn = re.sub("^[^_]*_", "", retn)
        retn = re.sub("_", " ", retn)
        return retn

    def cell(self, proposal, column_name):
        return "\n".join(
            [
                self.clean(at)
                for at in proposal.cell("Prospectus Appendix Attachments").split("\n")
            ]
        )


def main():
    """Compose the LFC input and emit it as html-ized csv."""
    try:
        opts, args = getopt.getopt(
            sys.argv[1:],
            "",
            [
                "proposals-csv=",
                "admin-review-csv=",
                "judge-evaluation-csv=",
                "wisehead-evaluation-csv=",
                "ots-metadata=",
                "sdgconfig-csv=",
                "tdc-config-dir=",
                "attachments-dir=",
                "correction-file=",
                "pare=",
                "csv-only",
            ],
        )
    except getopt.GetoptError as err:
        sys.stderr.write("ERROR: '%s'\n" % err)
        sys.exit(2)

    proposals_csv = None
    admin_review_csv = None
    judge_evaluation_csv = None
    wisehead_evaluation_csv = None
    regionconfig_csv = None
    sdgconfig_csv = None
    attachments_dir = None
    toc_dir = None
    ots_metadata_csv = None
    tdc_config_dir = None
    correction_files = []
    pare = None
    csv_only = False
    for o, a in opts:
        if o == "--proposals-csv":
            proposals_csv = a
        elif o == "--pare":
            pare = a
        elif o == "--csv-only":
            csv_only = True
        elif o == "--admin-review-csv":
            admin_review_csv = a
        elif o == "--judge-evaluation-csv":
            judge_evaluation_csv = a
        elif o == "--wisehead-evaluation-csv":
            wisehead_evaluation_csv = a
        elif o == "--ots-metadata":
            ots_metadata_csv = a
        elif o == "--sdgconfig-csv":
            sdgconfig_csv = a
        elif o == "--correction-file":
            correction_files.append(a)
        elif o == "--tdc-config-dir":
            tdc_config_dir = a
        elif o == "--attachments-dir":
            attachments_dir = a
        else:
            sys.stderr.write("ERROR: unrecognized option '%s'\n" % o)
            sys.exit(2)

    if proposals_csv is None:
        sys.stderr.write("ERROR: need --proposals-csv\n\n")
        sys.stderr.write(__doc__)
        sys.exit(1)

    comp = competition.Competition(
        proposals_csv, "LFC100Change2020", "Review Number", pare
    )
    comp.add_supplemental_information(competition.MediaWikiTitleAdder("Project Title"))
    comp.add_supplemental_information(competition.GlobalViewMediaWikiTitleAdder("100Change2020", "Project Title"))
    comp.add_supplemental_information(competition.StaticColumnAdder("Competition Name", "100Change2020"))

    fix_cell_processor = competition.FixCellProcessor()
    comp.process_all_cells_special(fix_cell_processor)
    fix_cell_processor.report()

    ots_metadata = process_ots_metadata(ots_metadata_csv)
    sdgconfig_data = process_sdgconfig_data(sdgconfig_csv)

    if judge_evaluation_csv is not None:
        comp.add_supplemental_information(
            competition.EvaluationAdder(
                "Judge",
                judge_evaluation_csv,
                app_col_name="Application #",
                score_rank_normalized_col_name="OverallScoreRankNormalized",
                sum_of_scores_normalized_col_name="SumOfScoresNormalized",
                trait_col_name="Trait",
                score_normalized_col_name="TraitScoreNormalized",
                comments_col_name="TraitJudgeComment",
                comments_score_normalized_col_name="TraitScoreNormalized",
            )
        )

    if wisehead_evaluation_csv is not None:
        comp.add_supplemental_information(
            competition.EvaluationAdder(
                "Wise Head",
                wisehead_evaluation_csv,
                app_col_name="Application #",
                score_rank_normalized_col_name="OverallScoreRankNormalized",
                sum_of_scores_normalized_col_name="SumOfScoresNormalized",
                trait_col_name="Trait",
                score_normalized_col_name="TraitScoreNormalized",
                comments_col_name="TraitJudgeComment",
                comments_score_normalized_col_name="TraitScoreNormalized",
            )
        )

    admin_review = competition.AdminReview(admin_review_csv, "Application #", "Status")
    comp.add_supplemental_information(admin_review)
    comp.filter_proposals(admin_review)

    comp.add_supplemental_information(TRDisqualifiedAdder(ots_metadata))
    comp.add_supplemental_information(WildcardEligibleAdder())
    comp.add_supplemental_information(WildcardAdder(ots_metadata))
    # Must come after TR DQed and Wildcard
    comp.add_supplemental_information(ApplicationLevelAdder())

    comp.process_cells_special("Priority Populations", competition.MultiLineProcessor())
    comp.process_cells_special(
        "Sustainable Development Goals",
        competition.MultiLineFromListProcessor([sdg["name"] for sdg in sdgconfig_data]),
    )

    for correction_file in correction_files:
        correction_processor = competition.CorrectionData(
            "Review Number", correction_file
        )
        for column in correction_processor.columns_affected():
            comp.process_cells_special(column, correction_processor)

    attachments = competition.RegexSpecifiedAttachments(
        comp.sorted_proposal_keys, attachments_dir
    )

    attachments.specify_new_column("Financial Attachment", "Financials Attachment")
    attachments.specify_new_column("Tech Review Attachment", "Tech Review Attachment")
    attachments.specify_new_column(
        ".*Tech Review Redacted.*", "Tech Review Redacted Attachment"
    )
    attachments.specify_new_column("MOU Attachment", "MOU Attachment")
    attachments.specify_new_column("Application Attachment", "Application Attachment")
    attachments.specify_new_column("COVID_.*", "COVID Response Attachment")
    attachments.specify_new_column(".*_Prospectus.pdf", "Prospectus Attachment")
    attachments.specify_new_column(".*_Overview.pdf", "Overview Attachment")
    attachments.specify_new_column(
        ".*_Appendix.*.pdf", "Prospectus Appendix Attachments", None, True
    )
    attachments.specify_new_column("Two Page Fact Sheet", "Fact Sheet Attachment")
    competition.BasicAttachments.defined_column_names = [
        "Other Attachment Display Names",
        "Other Attachments",
    ]
    for attachment in attachments.attachments:
        if (
            ots_metadata.get(attachment.key, {}).get("Financial Attachment", "")
            == attachment.file
        ):
            attachment.column_name = "Financials Attachment"
        elif (
            ots_metadata.get(attachment.key, {}).get("MOU Attachment", "")
            == attachment.file
        ):
            attachment.column_name = "MOU Attachment"
        elif (
            ots_metadata.get(attachment.key, {}).get("Tech Review Attachment", "")
            == attachment.file
        ):
            attachment.column_name = "Tech Review Attachment"
        elif (
            ots_metadata.get(attachment.key, {}).get("Two Page Fact Sheet", "")
            == attachment.file
        ):
            attachment.column_name = "Fact Sheet Attachment"
        elif (
            ots_metadata.get(attachment.key, {}).get("Application Attachment", "")
            == attachment.file
        ):
            attachment.column_name = "Application Attachment"
    comp.add_supplemental_information(attachments)
    comp.add_supplemental_information(AppendixDisplayNamesAdder())

    comp.sort("Wise Head Overall Score Rank Normalized", True)

    comp.add_toc(toc.GenericToc("Topic_TOC", "Primary Subject Area Category"))
    comp.add_toc(toc.GenericMultiLineToc("Population_TOC", "Priority Populations"))

    table_toc_formatter = toc.WikiTableTocProposalFormatter(
        [
            {
                "name": "Organization Legal Name",
                "heading": "Organization",
            },
            {
                "name": "Project Title",
                "heading": "Title",
                "link": True,
            },
            {
                "name": "Review Number",
                "heading": "ID #",
                "right_aligned": True,
            },
            {
                "name": "Wise Head Overall Score Rank Normalized",
                "heading": "Rank",
                "right_aligned": True,
            },
        ]
    )

    all_proposals = toc.ListToc("AllProposals")
    all_proposals.proposal_formatter = table_toc_formatter
    comp.add_toc(all_proposals)

    finalist_candidates = toc.ListToc("Finalist_Candidates")
    finalist_candidates.proposals = [
        p
        for p in comp.ordered_proposals()
        if (
            int(p.cell("Wise Head Overall Score Rank Normalized")) < 101
            or p.cell("Wild Card") == "Wild Card"
        )
        and p.cell("TR Disqualified") != "TR Disqualified"
    ]
    finalist_candidates.proposal_formatter = table_toc_formatter
    comp.add_toc(finalist_candidates)

    comp.add_toc(
        toc.RegionAwareGeographicToc(
            "Geographic_TOC",
            [
                ["Location Of Current Solution Country"],
                ["Location Of Current Solution2 Country"],
                ["Location Of Current Solution3 Country"],
                ["Location Of Current Solution4 Country"],
                ["Location Of Current Solution5 Country"],
                ["Location Of Future Work Country"],
                ["Location Of Future Work2 Country"],
                ["Location Of Future Work3 Country"],
                ["Location Of Future Work4 Country"],
                ["Location Of Future Work5 Country"],
            ],
        )
    )
    comp.add_toc(
        toc.GenericMultiLineToc(
            "SDG_TOC",
            "Sustainable Development Goals",
            [sdg["name"] for sdg in sdgconfig_data],
        )
    )

    comp.process_tocs()

    if tdc_config_dir is not None:
        create_tdc_config(tdc_config_dir, comp)

    my_wiki = wiki.WikiSession(
        config.username, config.password, comp.name, config.wiki_url
    )
    my_wiki.csv_only = csv_only
    my_wiki.upload_sheet(comp)
    my_wiki.upload_attachments(attachments.attachments)


if __name__ == "__main__":
    main()
